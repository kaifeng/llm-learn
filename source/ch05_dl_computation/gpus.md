# 使用 GPU 计算

深度学习模型，特别是大型模型，包含海量的计算，尤其是在训练过程中。现代的图形处理器（GPU）拥有数千个核心，能够执行大规模的并行计算，使其成为加速深度学习训练的理想硬件。

与主要用于执行顺序指令的 CPU 不同，GPU 的架构使其在处理矩阵和张量运算时效率极高。

本章将介绍：
- **确认 GPU 可用性**：如何检查当前环境中是否有可用的 GPU。
- **指定设备**：如何将张量和模型移动到 GPU 上进行计算。
- **多 GPU 计算**：对于非常大的模型或数据集，单块 GPU 可能不足以支持。我们将简要介绍如何在多块 GPU 上并行或分布式地训练模型。
