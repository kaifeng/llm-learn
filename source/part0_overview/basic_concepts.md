# 基本概念

机器学习分为监督学习、非监督学习、自监督学习和强化学习等。

**监督学习 (Supervised Learning)** 是最常见、最成熟的机器学习范式。

-   **核心思想**：模型从 **有标签（labeled）** 的数据中学习。数据集中的每个样本都包含一个输入特征（input）和一个期望的输出标签（output/label）。
-   **学习目标**：学习一个从输入到输出的映射函数。模型通过比较自己的预测输出和真实标签之间的差异（即“损失”），来不断调整自身参数，直到能对未见过的新输入做出准确的预测。
-   **主要任务**：监督学习主要解决两大类问题：分类和回归。
    -   **分类 (Classification)**：预测一个离散的类别。例如：判断一封邮件是否是垃圾邮件（二分类），或识别一张图片中的动物是猫、狗还是鸟（多分类）。 **逻辑回归（Logistic Regression）** 是解决这类问题的经典算法之一。
    -   **回归 (Regression)**：预测一个连续的数值。例如：根据房屋的面积、位置等特征预测其价格。**线性回归（Linear Regression）** 就是解决这类问题的经典算法之一。

-   **典型算法**：监督学习的算法非常丰富，包括：
    -   **用于分类的算法**：**逻辑回归（Logistic Regression）**、**决策树（Decision Tree）**、支持向量机（SVM）、K近邻（KNN）等。
    -   **用于回归的算法**：**线性回归（Linear Regression）**、决策树回归、支持向量回归等。
    决策树通过构建一个树状的决策模型来进行预测，具有很强的可解释性。

**非监督学习 (Unsupervised Learning)**

-   **核心思想**：模型从**没有标签**的数据中学习。它只能接触到输入数据，必须自己从中发现隐藏的结构、模式或关系。
-   **学习目标**：探索数据内在的结构。
-   **主要任务**：
    -   **聚类 (Clustering)**：将相似的数据点分到同一个簇（cluster）中。例如：根据用户的购买行为将其划分为不同的客户群体。
    -   **降维 (Dimensionality Reduction)**：在保留数据主要信息的前提下，减少数据的特征数量。例如：主成分分析（PCA）。

**自监督学习 (Self-Supervised Learning, SSL)** 是近年来推动大语言模型发展的关键技术，可以看作是无监督学习的一种特殊形式。

-   **核心思想**：同样使用**没有标签**的海量数据，但它巧妙地从数据本身中自动创建伪标签，从而将问题转化为一个监督学习问题来进行训练。
-   **学习目标**：通过解决一个精心设计的“借口任务（pretext task）”，来让模型学习到关于数据内在结构的、有价值的表示。好比一个学生拿到一张被撕碎的报纸，他通过学习如何将碎片拼接回完整的报纸（借口任务），从而学会了语法、词汇和常识（学到了表示）。
-   **在 LLM 中的应用**：
    -   **掩码语言模型 (Masked Language Modeling)**：随机遮盖句子中的一些词，然后让模型预测被遮盖的词是什么（BERT 使用的方式）。
    -   **下一词预测 (Next Token Prediction)**：根据一段文本的前半部分，让模型预测下一个词是什么（GPT 使用的方式）。

自监督学习是“预训练-微调”范式中**预训练**阶段的理论基础，它使得从未经标注的、海量的互联网文本中学习通用语言知识成为可能。

**强化学习 (Reinforcement Learning, RL)**

-   **核心思想**：模型（称为**智能体 Agent**）通过与一个**环境（Environment）**进行交互来学习。智能体在环境中做出**动作（Action）**，环境会相应地改变 **状态（State）** 并反馈给智能体一个 **奖励（Reward）** 或惩罚。
-   **学习目标**：学习一个最优**策略（Policy）**，即在什么状态下应该采取什么动作，以最大化长期累积的总奖励。好比训练一只宠物。当它做出正确的动作时，给它零食（正奖励）；当它做出错误动作时，不给奖励或进行轻微的惩罚。
-   **在 LLM 中的应用**：
    -   **基于人类反馈的强化学习 (RLHF)**：这是对齐（align）大语言模型、使其回答更有用、更无害的关键技术。人类对模型生成的多个回答进行偏好排序，这些排序被用来训练一个“奖励模型”，然后用这个奖励模型作为环境，通过强化学习来微调语言模型，使其更倾向于生成人类偏好的内容。

## 训练过程的关键概念

- **Batch (批次)**：由于整个数据集可能非常大，一次性将其全部加载到内存中并计算梯度是不现实的。因此通常将数据集分成若干个小的子集，这些子集被称为批次。深度学习框架主要采用的是无放回采样 (Sampling without Replacement) ，在一个 Epoch 开始时，将整个数据集（例如全部 1000 个样本）的索引进行一次完全的随机打乱，然后，按照打乱后的新顺序，从头到尾依次将数据切分成一个个批次。保证了每个样本在一个 Epoch 中恰好被使用一次。在某些特定的研究场景下可能会用到有放回采样 (Sampling with Replacement)，例如处理极度不均衡的数据集。
- **Iteration (迭代)**：指完成一次批次数据的前向传播、反向传播和参数更新的过程。这是参数更新的最小单位。
- **Epoch (轮次)**：指整个训练数据集中的所有样本都已经被模型处理了一遍。如果一个数据集有 1000 个样本，批次大小（Batch Size）为 100，那么一个 Epoch 就包含 10 次迭代。

## 训练与推理

模型训练完成后，即可用于推理，推理是使用训练好的模型对新数据进行预测。两者对比如下：

| 特征 | 训练 | 推理 |
| :--- | :--- | :--- |
| **过程** | 包括前向传播、计算损失、反向传播和参数更新。 | 只有前向传播。 |
| **数据** | 需要大量的**有标签**训练数据。 | 处理无标签的新数据。 |
| **计算成本**| 非常高，需要大量的计算资源和时间。 | 相对较低，速度快。 |
| **模型状态**| 模型参数在每次迭代中都会被修改。 | 模型参数是固定不变的。 |
| **特定技术**| Dropout、Batch Normalization 等技术处于“训练模式”，以帮助模型泛化。 | Dropout 被关闭，Batch Normalization 使用固定的统计值。 |
