# Softmax 回归

Softmax 回归（Softmax Regression）是逻辑回归（Logistic Regression）在多分类问题上的推广。它是一个基础且应用广泛的分类模型。

## 核心思想

与线性回归类似，Softmax 回归也首先计算输入特征的线性组合。但与逻辑回归使用 Sigmoid 函数将输出映射到 (0, 1) 区间不同，Softmax 回归使用 **Softmax 函数** 将一个包含任意实数的 K 维向量“压缩”成一个 K 维的概率分布。

对于一个有 K 个类别的分类问题，模型的输出是一个 K 维向量，其中第 i 个元素表示样本属于类别 i 的概率。

$$
p_i = \text{softmax}(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
$$

其中 $z$ 是线性模型的输出向量。

Softmax 函数确保了：
1.  每个类别的预测概率都在 (0, 1) 之间。
2.  所有类别的预测概率之和为 1。

模型的目标是最大化正确类别的预测概率，这通常通过最小化交叉熵损失函数来实现。
