# 线性回归

线性回归（Linear Regression）是机器学习中最基本且应用最广泛的回归模型之一。它通过学习一个线性函数来对输入特征和输出结果之间的关系进行建模。

## 核心思想

线性回归的核心假设是，输出变量可以表示为输入特征的线性组合。用数学公式表达，一个预测值 $\hat{y}$ 是通过以下方式计算的：

$$
\hat{y} = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b = \mathbf{w}^T \mathbf{x} + b
$$

其中：
- $\mathbf{x} = (x_1, x_2, ..., x_n)$ 是输入特征向量。
- $\mathbf{w} = (w_1, w_2, ..., w_n)$ 是模型的权重，表示每个特征的重要性。
- $b$ 是偏置项（bias）。
- 学习过程的目标就是找到最优的权重 $\mathbf{w}$ 和偏置 $b$，使得模型预测值与真实值之间的误差最小。这通常通过最小化均方误差（Mean Squared Error）损失函数来实现。

线性回归用于解决回归问题，即预测一个连续的数值输出。其目标是找到一条直线（或超平面），使其尽可能地拟合训练数据。

## 正则化

为了防止过拟合，可以在损失函数中加入正则化项，常见的有：
- **岭回归 (Ridge Regression)**：使用 L2 正则化。
- **Lasso 回归 (Lasso Regression)**：使用 L1 正则化。
