# RMSProp

RMSProp（Root Mean Square Propagation）是一种自适应学习率优化算法，旨在解决 Adagrad 学习率单调递减的问题。

## 核心思想

RMSProp 引入了梯度平方的指数加权移动平均，而不是简单地累积所有历史梯度平方。这使得模型能够更关注最近的梯度信息，从而避免学习率过早衰减。

## 更新规则

RMSProp 的更新规则如下：

1.  **计算梯度平方的指数加权移动平均**：
    $$ s_t = \beta s_{t-1} + (1 - \beta) (\nabla L(\mathbf{w}_t))^2 $$
    其中 $\beta$ 是衰减率（通常设置为 0.9）。

2.  **更新参数**：
    $$ \mathbf{w}_{t+1} = \mathbf{w}_t - \frac{\eta}{\sqrt{s_t + \epsilon}} \nabla L(\mathbf{w}_t) $$
    其中 $\eta$ 是学习率，$\epsilon$ 是一个很小的常数。

## 优势

- **解决学习率衰减问题**：通过指数加权移动平均，RMSProp 能够避免学习率过早衰减，从而在非凸优化问题上表现更好。
- **适用于非平稳目标**：在处理非平稳目标时，RMSProp 能够更好地适应梯度的变化。

## 劣势

- **需要手动调整学习率**：虽然自适应，但仍然需要手动调整全局学习率。
