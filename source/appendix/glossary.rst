.. _glossary:

术语
====

.. glossary::

    生成式AI（Generative AI）
        机器产生复杂有结构的物件，尽乎无法穷举。如文章、图像、语音等。不是生成式AI：分类（如垃圾邮件分类、猫狗分类）。

    多模态（multi modality）
        模态指信息的类型或格式，如文本、图像、音频、视频等。多模态指 AI 模型能够同时理解、处理和关联多种不同模态信息的能力。GPT-4V 就是一个典型的多模态模型。

    AR(Autoregressive Generation)
        自回归生成。这是一种生成序列数据（如文本）的方式，即逐个生成序列中的元素（token），并且每生成一个新的元素，都要依赖于所有在它之前已经生成的元素。这就像我们写句子一样，下一个词总是基于前面已经写好的内容。GPT 系列模型就是典型的自回归模型。这种方式生成的文本质量高、连贯性好，但缺点是速度较慢，因为必须串行生成。

    NAR(Non-Autoregressive Generation)
        非自回归生成。与自回归相反，这种方式试图一次性或并行地生成整个序列的所有元素，而不是逐个生成。例如，模型可能先预测目标句子的长度，然后同时填充所有位置的词语。这种方式生成速度极快，但通常会牺牲一定的文本质量和连贯性，因为它在预测某个位置的词时，并不知道其他位置的词是什么。

    ChatGPT(Generative Pre-trained Transformer)
        由 OpenAI 开发的著名对话式 AI 模型。它本身属于“生成式”、“预训练”、“Transformer”模型，其核心架构是“仅解码器（Decoder-only）”，因此它的生成方式是“自回归（AR）”的。ChatGPT 的革命性之处不仅在于其巨大的模型规模，更在于它通过“指令微调”和“基于人类反馈的强化学习（RLHF）”等对齐技术，使其能更好地理解人类意图并进行流畅、有帮助的对话。同类：Google Bard, Anthropic Claude

    Semi-Supervised Learning (SSL)
        半监督学习，一种机器学习范式，它结合了少量有标签数据和大量无标签数据进行训练。当获取大量标注数据成本高昂时，半监督学习能够利用易于获取的无标签数据来提升模型的性能和泛化能力。常见的技术包括自训练、协同训练和一致性正则化等。

    Transformer
        一种著名的深度学习模型，它最初是作为机器翻译的序列到序列模型提出的。后来，基于Transformer的预训练模型在各种自然语言处理任务上实现了最优性能，因此Transformer已经成为NLP中的主流架构。
        Transformer模型主要包括两部分：Encoder和Decoder。其中，Encoder负责编码输入序列，而Decoder负责生成输出序列。在编码过程中，每个词首先被转换为向量表示，然后通过多层的Encoder逐步传递信息，形成编码后的表示向量。在解码过程中，Decoder通过将编码后的表示向量与目标序列逐词匹配，生成输出序列。Transformer的核心技术是self-attention，它通过计算输入序列中不同位置之间的相关性，得到每个单词的权重，从而更好地捕捉输入序列中的重要信息。

    全连接层（Fully Connected Layer）
        简称 FC 层，也常被称为密集层（Dense Layer），是神经网络中最基本的一种层。在该层中，每一个输入神经元都与该层的所有输出神经元相连接。每个连接都有一个独立的权重。全连接层执行的操作本质上是一个线性变换（矩阵乘法），通常后面会跟着一个激活函数引入非线性。

    前馈神经网络（Feedforward Neural Network, FNN）
        指信息在网络中单向流动，从输入层经过隐藏层（如果有的话）到达输出层，没有任何循环或反馈连接。FNN可以包含各种类型的层，例如全连接层、卷积层、池化层等，只要信息流是单向的。它是一个非常通用的术语，描述了神经网络信息流动的基本方向。

    多层感知机(Multi-Layer Perceptron, MLP)
        是一种全连接的前馈神经网络。这意味着MLP中的每一层神经元都与前一层的所有神经元完全连接。MLP至少包含三层：一个输入层、一个或多个隐藏层和一个输出层。常在隐藏层中使用非线性激活函数，这使得MLP能够学习和表示复杂的非线性关系。最初的“感知机”是指一个单层网络，而“多层感知机”则扩展了这一概念，引入了隐藏层。

    神经架构搜索 (Neural Architecture Search, NAS)
        一种自动化机器学习（AutoML）技术，专注于自动设计神经网络的结构。传统上，网络结构（如层的类型、数量、连接方式）由人类专家手动设计，而 NAS 则通过算法来自动搜索一个在特定任务上表现最优的架构。它通常包含三大组件：定义所有可能架构的“搜索空间”，用于探索该空间的“搜索策略”（如强化学习、演化算法），以及用于评估每个被搜索到的架构性能的“评估策略”。
