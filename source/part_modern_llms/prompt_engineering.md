# 提示工程

**提示工程** 是围绕如何设计和优化提示的一系列技术和方法的总称，即不通过更新模型权重（微调）来让模型适应任务，而是通过精心设计输入给模型的 **提示（Prompt）** 来引导其行为。

一个好的提示通常具备以下特点：

1.  **清晰明确**：避免使用模糊的语言。明确地告诉模型你想要什么，包括格式、长度、风格、角色等。
    -   **反例**：`写一些关于狗的东西。`
    -   **正例**：`以一个资深宠物医生的身份，写一篇 300 字左右的短文，介绍新手主人应该如何为他们的拉布拉多幼犬选择合适的狗粮。`

2.  **提供上下文**：给模型足够的背景信息，帮助它理解任务所处的环境。
    -   **反例**：`总结一下这个会议。`
    -   **正例**：`我是一个项目的项目经理，错过了今天上午关于“阿尔法项目”的启动会。请根据以下会议纪要，为我总结出最重要的三个决定和各自的负责人。`

3.  **简化任务**：如果一个任务很复杂，可以将其分解为一系列更简单的子任务，然后通过提示链（prompt chaining）来逐步完成。

## 常用提示技巧

### 1. 零样本、少样本与单样本提示

-   **零样本 (Zero-shot)**：直接向模型提出请求，不提供任何示例。这依赖于模型在预训练和指令微调阶段学到的通用能力。
    -   `将“我爱人工智能”翻译成法语。`

-   **单样本 (One-shot)** / **少样本 (Few-shot)**：在提出最终请求之前，给模型提供一个或多个完整的“指令-回答”示例。这有助于模型更好地理解任务的格式和期望的输出风格，是上下文学习的核心。
    -   **示例（少样本）**：
        ```
        将句子从非正式改为正式。
        非正式: 这事儿得抓紧办。
        正式: 此事需要尽快处理。

        非正式: 他把那活儿搞砸了。
        正式: 他未能成功完成那项任务。

        非正式: 你看咋样？
        正式:
        ```
        模型会根据示例的模式，续写出 `您认为如何？` 或类似答案。

### 2. 思维链 (Chain-of-Thought, CoT)

思维链提示是一种旨在提升模型在复杂推理任务（如数学应用题、逻辑推理）上表现的强大技术。

**核心思想**：在要求模型给出最终答案之前，先引导它“一步一步地思考”，将解决问题的中间推理过程也作为回答的一部分。这模仿了人类解决复杂问题时的思考方式。

-   **示例（零样本 CoT）**：
    ```
    问题：一个杂货店有 23 个苹果。如果他们用了 20 个来做午餐，又买了 6 个，现在他们有多少个苹果？

    请一步一步地思考，然后给出最终答案。
    ```
    模型可能会生成：
    ```
    好的，我来一步步分析：
    1.  开始时有 23 个苹果。
    2.  用了 20 个，所以剩下 23 - 20 = 3 个苹果。
    3.  又买了 6 个，所以现在有 3 + 6 = 9 个苹果。

    最终答案是 9 个。
    ```

通过显式地输出推理链条，模型犯错的几率会降低，并且其推理过程也变得更加透明和可验证。

### 3. 赋予角色

在提示的开头明确指定模型扮演一个角色，可以有效地引导其回答的风格、口吻和知识领域。

-   `你是一位经验丰富的旅行博主，请为我规划一个为期三天的巴黎浪漫之旅，重点是美食和艺术。`
-   `你是一个 Python 编程专家，请检查以下代码中的错误，并以代码审查（Code Review）的格式给出修改建议。`

## 模型参数

除了设计提示词本身，还可以通过调整模型的生成参数来精细地控制输出结果。这些参数通常在调用模型 API 时设置，常见的有：

-   **Temperature**：温度系数，用于调节生成文本的随机性。较高的温度（如 0.8）会让模型的输出更具多样性和创造性，但也可能包含更多事实错误或不相关的内​​容。较低的温度（如 0.2）会使输出更具确定性和一致性，更贴近模型认为最可能的回答。

-   **Top-K Sampling**：在每一步生成中，模型只从概率最高的 K 个词中进行抽样。这可以防止模型选择非常不靠谱的词，但可能会限制其创造力。

-   **Top-P (Nucleus) Sampling**：选择一个概率累积超过 P 的最小词集，然后从这个“核心”词集中进行抽样。这是一种更动态的方法，在模型高度自信时，候选词集会很小；在模型不确定时，候选词集会变大，从而在保证质量和激发创造性之间取得平衡。

当 Top-K 和 Top-P 一起使用时，系统会先应用 Top-K 过滤，得到一个不超过 K 个候选词的列表，然后再对这个列表应用 Top-P 过滤，最终从得到的更小的集合中进行抽样。这相当于取两个集合的交集，是一种更严格的筛选方式。
