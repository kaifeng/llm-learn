# AI技术栈

现代 AI（尤其是大语言模型）的生态系统从下至上可以大致划分为几个层次：

- 硬件与驱动层。这是所有计算的基础，为 AI 模型的训练和推理提供必需的算力。这一层执行海量的并行计算，尤其是矩阵乘法。例如：

  -   **NVIDIA GPUs**: 目前 AI 领域绝对的主导者，如 A100, H100 系列。
  -   **Google TPUs**: Google 自主研发的、为加速其内部（尤其是 TensorFlow）模型而设计的专用芯片。
  -   **CUDA**: NVIDIA 创建的并行计算平台和编程模型，是其硬件生态的护城河。

- 训练/微调框架层。这一层提供了构建和训练神经网络的底层工具和库。开发者使用它们来定义模型架构、执行反向传播和参数优化，是深度学习研究和开发的基础语言。例如：

  -   **PyTorch**: 由 Meta 主导的开源框架，以其灵活性、易用性和庞大的社区生态而成为目前学术界和工业界的首选。
  -   **TensorFlow**: 由 Google 开发的框架，以其强大的生产部署能力和生态系统（如 TFX）而闻名。
  -   **JAX**: Google 的另一个高性能数值计算库，结合了 Autograd 和 XLA，在研究社区中越来越受欢迎。

- 模型层。这一层是预训练好的、具备通用能力的模型本身，它们提供基础的感知、理解、推理和生成能力，是 AI 应用的“智慧核心”，但通常不直接面向最终用户。例如：

  -   **语言模型**: GPT 系列 (OpenAI), Llama 系列 (Meta), Claude 系列 (Anthropic), Gemini 系列 (Google), Mistral 系列。
  -   **视觉模型**: **Stable Diffusion**, Midjourney, DALL-E 系列。

- 模型服务与推理优化层。当模型训练好后，需要将其部署为可供调用的服务。这一层负责将模型部署为服务，并进行性能优化，是模型的“高性能引擎”，专注于让这个服务过程更高效。例如：

  -   **vLLM**: 一个开源的高性能 LLM 推理和部署服务引擎。其核心技术 PagedAttention 极大地提升了推理的吞吐量和内存效率。
  -   **TensorRT-LLM**: NVIDIA 官方推出的推理优化库，深度集成自家硬件，提供极致性能。
  -   **Text Generation Inference (TGI)**: 由 Hugging Face 推出的主流 LLM 服务解决方案。

- 应用框架层。这一层负责编排复杂的业务逻辑和任务流，将模型的能力与外部数据和工具结合起来。帮助开发者快速构建、组合和管理 LLM 应用的逻辑。例如：

  -   **LangChain**: 最具代表性的 LLM 应用开发框架，提供了丰富的组件、链（Chains）和代理（Agents）来构建复杂的应用。
  -   **LlamaIndex**: 一个专注于 RAG（检索增强生成）的“数据框架”。它在连接 LLM 与外部数据方面（如数据加载、索引、查询）尤其强大。

- 应用层。将底层的 AI 能力封装成易于使用的产品或服务，是最终用户直接交互、解决特定问题的产品。例如：

  -   **对话机器人**: ChatGPT, Claude.ai。
  -   **AI 绘画工具**: Midjourney, ComfyUI。
  -   **本地模型运行工具**: **Ollama**。
  -   **编程助手**: GitHub Copilot。
