# 自动并行

随着深度学习模型规模的不断增大，单台设备（如单个 GPU）往往无法满足其计算和内存需求。自动并行（Automatic Parallelism）技术旨在将模型的训练和推理任务自动分配到多个设备或多台机器上，从而提高计算效率和处理更大规模的模型。

## 核心思想

自动并行技术的目标是让开发者无需手动编写复杂的并行代码，框架能够自动识别模型中的并行机会，并将其高效地分发到可用的计算资源上。

## 常见的并行策略

- **数据并行 (Data Parallelism)**：这是最常见的并行策略。每个设备都拥有模型的完整副本，但每个设备处理不同批次的数据。梯度在每个设备上独立计算，然后进行聚合（如求平均），再用于更新所有设备的模型参数。
- **模型并行 (Model Parallelism)**：当模型太大无法放入单个设备的内存时，可以将模型的不同层或不同部分放置在不同的设备上。数据在设备之间流动，每个设备只负责模型的一部分计算。
- **流水线并行 (Pipeline Parallelism)**：结合了数据并行和模型并行。将模型划分为多个阶段，每个阶段由不同的设备处理。数据以流水线的方式在设备之间传递，从而提高硬件利用率。

## 深度学习框架中的实现

现代深度学习框架（如 PyTorch Distributed, TensorFlow Distributed）提供了丰富的 API 和工具来支持自动并行，使得开发者能够相对容易地利用多设备或多机器的计算能力来训练大型模型。
