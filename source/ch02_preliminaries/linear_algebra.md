# 线性代数

线性代数是机器学习的语言，几乎所有的数据和模型操作都可以用线性代数的概念来表达。

-   **核心概念**：
    -   **标量 (Scalar)**：单个数值。
    -   **向量 (Vector)**：一维数组，表示空间中的一个点或方向。在机器学习中，一个样本的特征通常表示为一个向量。
    -   **矩阵 (Matrix)**：二维数组，由行和列组成。数据集通常表示为一个矩阵，神经网络的权重也表示为矩阵。
    -   **张量 (Tensor)**：多维数组，是向量和矩阵的推广。深度学习中，数据和模型参数通常以张量的形式存在。
-   **基本运算**：
    -   **加法与减法**：向量和矩阵的对应元素相加减。
    -   **乘法**：
        -   **标量乘法**：标量与向量/矩阵的每个元素相乘。
        -   **点积 (Dot Product)**：两个向量的对应元素相乘再求和，结果是标量。用于计算相似度、投影等。
        -   **矩阵乘法**：矩阵之间按照特定规则相乘，结果是矩阵。神经网络中层与层之间的计算核心。
    -   **转置 (Transpose)**：矩阵的行和列互换。
    -   **逆 (Inverse)**：矩阵的逆用于求解线性方程组。
-   **应用**：数据表示、特征工程、主成分分析（PCA）、神经网络的层运算、损失函数计算。

### The Art of Linear Algebra

这份名为《线性代数的艺术》的笔记，是日本学者 Kenji Hiranabe 基于 MIT 教授 Gilbert Strang 的著作《每个人的线性代数》制作的。它将原著浓缩成仅 12 页的图解笔记，内容涵盖了从理解矩阵的四个视角、基本运算（如向量与矩阵乘法）、实用技巧到矩阵的五种分解方式。这份笔记因其精炼和可视化，获得了 Gilbert Strang 本人的高度肯定，并被收录进原书介绍页面的推荐链接中。

项目地址：https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra

参考链接：https://news.mit.edu/2023/gilbert-strang-made-linear-algebra-fun-0531
