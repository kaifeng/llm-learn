# 自动微分

自动微分（Automatic Differentiation，简称 Autograd）是深度学习框架的核心功能之一。它能够自动计算复杂函数（如神经网络）中任意参数的梯度，从而使我们免于手动推导和实现反向传播算法。

## 核心思想

深度学习模型的训练依赖于梯度下降等优化算法，而这些算法需要计算损失函数对模型参数的梯度。自动微分通过记录计算图（Computational Graph）来精确地计算这些梯度。

- **计算图**：当执行一个操作时（如矩阵乘法），框架会构建一个图，记录下输入、输出和操作之间的关系。
- **反向传播**：在计算完损失后，可以调用一个 `.backward()` 方法。框架会从损失节点开始，沿着计算图反向传播，并利用链式法则计算出每个参数节点的梯度。

本章将介绍自动微分的原理，以及如何在深度学习框架中使用它来为模型训练获取梯度。这是理解和实现反向传播算法的基础。
