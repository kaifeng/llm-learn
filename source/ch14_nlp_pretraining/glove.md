# 词嵌入的预训练 (GloVe)

GloVe（Global Vectors for Word Representation）是由 Stanford 大学在 2014 年提出的一种词嵌入模型。它结合了两种方法的优点：既利用了全局的统计信息（词的共现矩阵），又利用了局部的上下文信息。

## 核心思想

GloVe 的核心思想是：词向量应该能够通过简单的数学运算（如点积）来反映词语的共现统计信息。它通过对一个巨大的“词-词共现矩阵”进行分解，来学习词向量。

- **共现矩阵**：记录了语料库中每个词与它周围的词共同出现的频率。例如，如果“猫”和“狗”经常一起出现，那么它们在共现矩阵中的值就会很高。

GloVe 模型的目标是学习词向量，使得任意两个词的词向量的点积，能够近似地等于它们在共现矩阵中对数共现频率的比值。

## GloVe 与 Word2Vec 的对比

- **Word2Vec**：是一个“局部”窗口方法，它通过预测局部上下文来学习词向量，没有直接利用全局的共现统计信息。
- **GloVe**：是一个“全局”方法，它直接对全局的共现统计信息进行建模，通过分解共现矩阵来学习词向量。

## 优势

- **结合全局与局部信息**：GloVe 能够有效地结合全局的共现统计信息和局部的上下文信息，从而学习到高质量的词向量。
- **性能优异**：在许多词语相似度、类比推理等任务上，GloVe 表现出与 Word2Vec 相当甚至更好的性能。

GloVe 为词嵌入的学习提供了一个不同的视角，并成为词嵌入领域的重要基准模型之一。
