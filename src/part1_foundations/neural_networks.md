# 神经网络

神经网络（Neural Networks）是深度学习的核心构建块。神经网络的基本计算单元是神经元（或称为节点）。一个简化的神经元模型如下：

经元接收来自其他神经元或外部数据源的多个输入信号（$x_1, x_2, ..., x_n$）。每个输入信号都有一个关联的**权重（weight, $w_i$）**，代表该输入的重要性。神经元将所有输入的加权值相加，并加上一个**偏置（bias, $b$）**。偏置允许我们微调输出，可以看作是激活函数的触发阈值。

$$ z = (w_1x_1 + w_2x_2 + ... + w_nx_n) + b = \sum_{i=1}^{n} w_ix_i + b $$

加权求和的结果会被送入一个非线性的激活函数得到该神经元的最终输出 $$ a = f(z) $$。

激活函数的作用是向网络中引入非线性。否则，无论神经网络有多少层，最终输出都只是输入的线性组合，无法学习复杂的数据模式。

## 神经网络的层次结构

将神经元组织成层次结构就能构建出强大的神经网络。一个典型的神经网络由输入层、隐藏层和输出层组成：

**输入层（Input Layer）** 接收原始数据。该层的神经元数量通常等于数据特征的数量。

**隐藏层（Hidden Layers）** 位于输入层和输出层之间。这些层负责提取数据中的各种特征。一个神经网络可以没有隐藏层（如逻辑回归），也可以有一个或多个隐藏层。拥有多个隐藏层的网络通常被称为“深度神经网络”（Deep Neural Networks）。

**输出层（Output Layer）** 产生最终的预测结果。该层的神经元数量和激活函数取决于具体的任务。回归任务通常只有一个输出神经元，且不使用或使用线性激活函数。
分类任务的输出神经元的数量等于类别的数量，通常使用 Softmax 将输出转换为概率分布。

## 神经网络如何学习

神经网络的学习过程本质上是一个参数优化的过程，目标是找到一组最佳的权重和偏置，使得网络对给定输入的预测结果与真实标签之间的损失最小。

这个过程通常通过一个称为 **梯度下降（Gradient Descent）** 的算法来迭代完成：

1.  **前向传播（Forward Propagation）**：将一批训练数据输入网络，数据从输入层流向输出层，最终得到预测结果。

2.  **计算损失（Loss Calculation）**：使用一个**损失函数**（如均方误差或交叉熵）来量化预测结果与真实标签之间的差距。

3.  **反向传播（Backpropagation）**：这是学习过程的核心。算法会从输出层开始，反向计算损失函数相对于网络中每一个权重和偏置的梯度（偏导数）。这个梯度指明了参数调整的方向，以最快地减小损失。

4.  **参数更新（Weight Update）**：使用优化器（如 Adam、SGD）根据计算出的梯度来更新网络中的所有权重和偏置。

这个“前向传播 -> 计算损失 -> 反向传播 -> 参数更新”的循环会重复进行，直到网络的性能达到满意的水平。

Epoch, Batch, Iteration是训练过程的几个关键概念

- **Batch (批次)**：由于整个数据集可能非常大，一次性将其全部加载到内存中并计算梯度是不现实的。因此通常将数据集分成若干个小的子集，这些子集被称为批次。
- **Iteration (迭代)**：指完成一次批次数据的前向传播、反向传播和参数更新的过程。这是参数更新的最小单位。
- **Epoch (轮次)**：指整个训练数据集中的所有样本都已经被模型“过”了一遍。例如，如果一个数据集有 1000 个样本，批次大小（Batch Size）为 100，那么一个 Epoch 就包含 10 次迭代（1000 / 100 = 10）。

完整的训练过程是：在多个 Epoch 中，每个 Epoch 都包含多次迭代，每次迭代处理一个 Batch 的数据来更新模型的权重。

训练过程从数据中学习，找到最佳的模型参数（权重和偏置）。推理过程则是使用训练好的模型对新数据进行预测。

| 特征 | 训练 | 推理 |
| :--- | :--- | :--- |
| **过程** | 包括前向传播、计算损失、反向传播和参数更新。 | 只有前向传播。 |
| **数据** | 需要大量的**有标签**训练数据。 | 处理无标签的新数据。 |
| **计算成本**| 非常高，需要大量的计算资源和时间。 | 相对较低，速度快。 |
| **模型状态**| 模型参数在每次迭代中都会被修改。 | 模型参数是固定不变的。 |
| **特定技术**| Dropout、Batch Normalization 等技术处于“训练模式”，以帮助模型泛化。 | Dropout 被关闭，Batch Normalization 使用固定的统计值。 |

## 全连接层

**全连接层**（Fully Connected Layer，简称 FC 层），也常被称为密集层（Dense Layer），是神经网络中最基本的一种层。在该层中，每一个输入神经元都与该层的所有输出神经元相连接。每个连接都有一个独立的权重。全连接层执行的操作本质上是一个线性变换（矩阵乘法），通常后面会跟着一个激活函数引入非线性。

## 前馈神经网络

**前馈神经网络**（Feedforward Neural Network，简称 FFN），是一种最基础的神经网络架构类型。它的特点是信息在网络中单向流动，从输入层经过一个或多个隐藏层，最终到达输出层，没有循环或反馈连接。一个典型的前馈神经网络通常由多个全连接层堆叠而成，层与层之间通过激活函数连接。

## 多层感知机

**多层感知机** (Multi-Layer Perceptron, MLP) 是前馈神经网络的一种具体实现，也是最基础和最经典的深度神经网络形态。当我们将输入层、至少一个隐藏层和输出层堆叠在一起，并且层与层之间的神经元是全连接的，这种网络结构就被称为 MLP。全连接神经网络（FNN）通常指的就是 MLP。它是后续更复杂的网络结构（如 CNN, RNN）的基础。

# 激活函数

激活函数是神经网络中的一个关键组件。它被应用于神经元的输出，为其引入非线性。如果没有非线性激活函数，无论神经网络有多少层，其本质上都只是一个线性模型，无法学习和表示复杂的数据模式。
激活函数决定了神经元在接收到特定输入后是否应该被“激活”或“点燃”，以及它应该向下一层传递什么强度的信号。

- **Sigmoid** 函数将任意实数输入压缩到 (0, 1) 的范围内，可以被解释为概率，常用于二分类问题的输出层或作为门控机制（如 LSTM 中的门）。

  $$ f(x) = \frac{1}{1 + e^{-x}} $$

  但是当输入值非常大或非常小时，函数的梯度会趋近于0，在反向传播过程中，会导致深层网络的梯度信号变得非常微弱，使得网络难以训练。

- **Tanh** (双曲正切) 函数可以看作是 Sigmoid 函数的一个缩放和移位版本，它将输入压缩到 (-1, 1) 的范围内。通常比 Sigmoid 函数有更好的性能，收敛速度更快，但仍然存在梯度消失的问题。

  $$ f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $$

- **ReLU** 是目前在深度学习的隐藏层中最常用的激活函数，只涉及一个简单的阈值操作。

  $$ f(x) = \max(0, x) $$

  当输入为正数时，其梯度恒为 1，这使得梯度能够很好地在网络中传播。但是，如果一个神经元的输入在训练过程中持续为负，那么它的梯度将永远为0，导致该神经元的权重无法再被更新。

- **Leaky ReLU** 是对 ReLU 的改进，它允许在输入为负时也有一个小的、非零的梯度。$\alpha$ 是一个很小的常数（如 0.01）。

  $$ f(x) = \begin{cases} x & \text{if } x > 0 \\ \alpha x & \text{if } x \le 0 \end{cases} $$

- **Softmax** 的作用是将一个包含任意实数值的向量（称为 logits）转换为一个概率分布。每个元素的值都在 (0, 1) 之间，并且所有元素的总和为 1。
  这使得模型的输出可以直接解释为输入样本属于每一个类别的概率，专门用于多分类问题的输出层。

  $$ \sigma_i = \frac{e^{z_i}}{\sum_{j=1}^{n}e^{z_j}}, \quad i=1,2,...,n $$


# 损失函数

**损失函数**定义了模型要优化的目标，即衡量模型预测值与真实值之间的差距。损失函数输出一个数值，该数值代表了单次预测的好坏程度。损失值越大，说明模型的预测越不准确。训练的目标就是最小化损失值。不同类型的任务需要使用不同的损失函数。

回归任务的目标是预测一个连续值。

- **均方误差 (Mean Squared Error, MSE)**：也称为 L2 损失。它计算的是预测值与真实值之差的平方的平均值。由于平方的存在，MSE 对较大的误差给予更重的惩罚。
    $$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $$

- **平均绝对误差 (Mean Absolute Error, MAE)**：也称为 L1 损失。它计算的是预测值与真实值之差的绝对值的平均值。相比 MSE，MAE 对异常值不那么敏感，鲁棒性更强。
    $$ \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| $$

分类任务的目标是预测一个离散的类别。

- **交叉熵损失 (Cross-Entropy Loss)**：是分类任务中最常用的损失函数。它衡量的是模型预测的概率分布与真实的概率分布之间的差异。

    - **二元交叉熵 (Binary Cross-Entropy)**：用于二分类问题（例如，是/不是垃圾邮件）。此时，输出层只有一个神经元，并使用 Sigmoid 激活函数输出一个概率值 $p$。
        $$ L = -[y \log(p) + (1-y) \log(1-p)] $$
        其中 $y$ 是真实标签（0 或 1），$p$ 是模型预测为类别 1 的概率。

    - **分类交叉熵 (Categorical Cross-Entropy)**：用于多分类问题（例如，手写数字 0-9 识别）。此时，输出层有 N 个神经元（N 为类别数），并使用 Softmax 激活函数输出一个概率分布。
        $$ L = -\sum_{i=1}^{N} y_i \log(p_i) $$
        其中 $y_i$ 是一个独热编码的真实标签，$p_i$ 是模型预测为类别 $i$ 的概率。

# 优化器

优化器是根据反向传播计算出的梯度来更新网络参数（权重和偏置）的算法，它的目标是找到一组能使损失函数最小化的参数。

## 梯度下降

梯度下降(Gradient Descent)是所有优化算法的基础。其核心思想是：**沿着梯度下降最快的方向（梯度的反方向）调整参数，从而逐步减小损失值。**

更新规则如下：
`新参数 = 旧参数 - 学习率 × 梯度`

**学习率 (Learning Rate)** 是一个超参数，它控制着每次参数更新的步长。学习率过大可能导致模型在最优点附近震荡甚至发散；学习率过小则会导致模型收敛速度过慢。

根据每次更新使用的数据量，梯度下降分为三种变体：

1.  **批量梯度下降 (Batch Gradient Descent)**：每次更新都使用整个训练集的数据。计算精确但速度慢，且需要大量内存。
2.  **随机梯度下降 (Stochastic Gradient Descent, SGD)**：每次更新仅使用训练集中的一个样本。速度快，但更新方向不稳定，损失函数会剧烈波动。
3.  **小批量梯度下降 (Mini-batch Gradient Descent)**：是上述两者的折中，也是最常用的方法。每次更新使用一小批（mini-batch）数据（如 32, 64, 128 个样本）。它兼顾了计算效率和更新的稳定性。

## 高级优化器

为了解决 SGD 的一些问题（如容易陷入局部最优、收敛速度慢等），研究者们提出了许多更先进的优化器。

- **Momentum**：引入了“动量”的概念。它在更新参数时，不仅考虑当前的梯度，还考虑了历史的更新方向。这有助于加速收敛并冲出局部最优。就像一个从山上滚下来的球，它会保持之前的速度。

- **Adam (Adaptive Moment Estimation)**：是目前最流行、最常用的优化器之一。它结合了 Momentum 和另一种名为 RMSprop 的优化器的思想，能够为网络中的每一个参数计算自适应的学习率。Adam 通常能快速收敛，并且对超参数的选择不那么敏感，是许多任务的默认首选。

# 反向传播的梯度计算

反向传播（Backpropagation）是神经网络训练的核心算法，其本质是利用链式法则计算损失函数对各层参数的梯度。
下面通过一个具体的两层神经网络实例，展示梯度计算的全过程。

### 一、神经网络结构与参数设定
**网络结构** ：输入层（2节点）→ 隐藏层（2节点）→ 输出层（1节点）
**激活函数** ：隐藏层和输出层均使用sigmoid函数：
$\sigma(x)=1+e^{-x}1​,\sigma'(x)=\sigma(x)(1-\sigma(x))$

**输入数据** ：$X = [1, 2]$，真实标签：$y = 0.5$

**初始参数** ：
隐藏层权重：$W_1 = \begin{bmatrix}0.5 & 0.6 \ 0.7 & 0.8\end{bmatrix}$，偏置：$b_1 = [0.1, 0.2]$
输出层权重：$W_2 = [0.9, 0.1]$，偏置：$b_2 = 0.3$

### 二、前向传播计算（Forward Propagation）

1. **隐藏层输入与输出**

隐藏层加权和：

$z_1 = X \cdot W_1 + b_1 = [1, 2] \cdot \begin{bmatrix}0.5 & 0.6 \ 0.7 & 0.8\end{bmatrix} + [0.1, 0.2] = [1 \times 0.5 + 2 \times 0.7 + 0.1, \, 1 \times 0.6 + 2 \times 0.8 + 0.2] = [2.0, 2.4]$

隐藏层激活值：
$a_1 = \sigma(z_1) = \left[\frac{1}{1+e^{-2.0}}, \frac{1}{1+e^{-2.4}}\right] \approx [0.8808, 0.9084]$

2. **输出层输入与输出**

输出层加权和：

$z_2 = a_1 \cdot W_2^T + b_2 = [0.8808, 0.9084] \cdot [0.9, 0.1]^T + 0.3 = 0.8808 \times 0.9 + 0.9084 \times 0.1 + 0.3 \approx 1.1835$

输出层预测值：

$\hat{y} = \sigma(z_2) = \frac{1}{1+e^{-1.1835}} \approx 0.7692$

### 三、反向传播计算

**损失函数** ：均方误差（MSE）

$L = \frac{1}{2}(\hat{y} - y)^2 = \frac{1}{2}(0.7692 - 0.5)^2 \approx 0.035$

1. **计算输出层的误差项（δ₂）**

损失对输出的导数：

$\frac{\partial L}{\partial \hat{y}} = (\hat{y} - y) = 0.7692 - 0.5 = 0.2692$

输出对加权和的导数（sigmoid导数）：

$\frac{\partial \hat{y}}{\partial z_2} = \sigma'(z_2) \approx 0.7692 \times (1 - 0.7692)\approx 0.1776$

输出层误差项（链式法则）：

$\delta{_2} = \frac{\partial L}{\partial z_2} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z_2} \approx 0.2692 \times 0.1776 \approx 0.0478$

2. **计算隐藏层到输出层的权重梯度（∂L/∂W₂）和偏置梯度（∂L/∂b₂）**

权重梯度：$\frac{\partial L}{\partial W_2} = \delta{_2} \cdot a_1 = 0.0478 \times [0.8808, 0.9084] \approx [0.0421, 0.0434]$

偏置梯度：$\frac{\partial L}{\partial b_2} = \delta{_2} \approx 0.0478$

3. **计算隐藏层的误差项（δ₁）**

损失对隐藏层激活值的导数：

$\frac{\partial L}{\partial a_1} = \delta{_2} \cdot W_2 = 0.0478 \times [0.9, 0.1] \approx [0.0430, 0.0048]$

隐藏层激活对加权和的导数（sigmoid导数）：

$\frac{\partial a_1}{\partial z_1} = \sigma'(z_1) \approx [0.8808 \times 0.1192, \, 0.9084 \times 0.0916] \approx [0.1051, 0.0833]$

隐藏层误差项：

$\delta{_1} = \frac{\partial L}{\partial z_1} = \frac{\partial L}{\partial a_1} \cdot \frac{\partial a_1}{\partial z_1} \approx [0.0430 \times 0.1051, \, 0.0048 \times 0.0833] \approx [0.0045, 0.0004]$

4. **计算输入层到隐藏层的权重梯度（∂L/∂W₁）和偏置梯度（∂L/∂b₁）**

- 权重梯度

  $\frac{\partial L}{\partial W_1} = \delta{_1}^T \cdot X = \begin{bmatrix}0.0045 \\ 0.0004\end{bmatrix} \cdot [1, 2] = \begin{bmatrix}0.0045 \times 1 & 0.0045 \times 2 \\ 0.0004 \times 1 & 0.0004 \times 2\end{bmatrix} \approx \begin{bmatrix}0.0045 & 0.0090 \\ 0.0004 & 0.0008\end{bmatrix}$

- 偏置梯度

  $\frac{\partial L}{\partial b_1} = \delta{_1} \approx [0.0045, 0.0004]$

### 四、梯度汇总与参数更新

|     参数 |                                                   梯度值（近似） |
|:-------|:-----------------------------------------------------------------|
| $W_2$ |                                               $[0.0421, 0.0434]$ |
| $b_2$ |                                                         $0.0478$ |
| $W_1$ | $\begin{bmatrix}0.0045 & 0.0090 \\ 0.0004 & 0.0008\end{bmatrix}$ |
| $b_1$ |                                               $[0.0045, 0.0004]$ |

**参数更新（假设学习率η=0.1）**：

- $W_2 \leftarrow W_2 - \eta \cdot \frac{\partial L}{\partial W_2} \approx [0.9-0.0042, 0.1-0.0043] = [0.8958, 0.0957]$
- $b_2 \leftarrow b_2 - \eta \cdot \frac{\partial L}{\partial b_2} \approx 0.3 - 0.0048 = 0.2952$
- $W_1 \leftarrow W_1 - \eta \cdot \frac{\partial L}{\partial W_1} \approx \begin{bmatrix}0.5-0.0005 & 0.6-0.0009 \\ 0.7-0.00004 & 0.8-0.00008\end{bmatrix} \approx \begin{bmatrix}0.4995 & 0.5991 \\ 0.6996 & 0.7999\end{bmatrix}$
- $b_1 \leftarrow b_1 - \eta \cdot \frac{\partial L}{\partial b_1} \approx [0.1-0.0005, 0.2-0.00004] = [0.0995, 0.19996]$

### 四、反向传播核心逻辑总结

1. **前向传播**：从输入层到输出层计算各层激活值，得到预测值。
2. **误差反向传递**：从输出层开始，利用链式法则计算各层误差项（δ），其中：
- 输出层误差：$\delta{_2} = (\hat{y}-y) \cdot \sigma'(z_2)$
- 隐藏层误差：$\delta{_k} = \delta{_{k+1}} \cdot W_{k+1}^T \cdot \sigma'(z_k)$（k为隐藏层序号）
3. **梯度计算**：
- 权重梯度：$\frac{\partial L}{\partial W_k} = \delta{_k}^T \cdot a_{k-1}$
- 偏置梯度：$\frac{\partial L}{\partial b_k} = \delta{_k}$

可以看出，反向传播的本质是将输出误差逐层分解为各层参数的梯度，从而为梯度下降优化提供方向。

## 梯度消失与梯度爆炸

在深度神经网络的训练过程中，尤其是在网络层数较深或使用某些特定的激活函数时，反向传播算法可能会遇到两个主要问题：**梯度消失（Vanishing Gradient）**和**梯度爆炸（Exploding Gradient）**。

### 梯度消失

- **现象**：在反向传播过程中，梯度值随着网络层数的增加而指数级减小，导致靠近输入层的网络层（即浅层）的参数更新变得非常缓慢甚至停滞。这意味着浅层网络几乎无法学习到有用的特征。
- **原因**：
    1.  **链式法则的乘法效应**：在反向传播中，梯度是通过链式法则逐层相乘得到的。如果每层的梯度（例如，激活函数的导数）都小于 1，那么经过多层相乘后，梯度会迅速趋近于 0。
    2.  **激活函数**：传统的激活函数如 Sigmoid 和 Tanh，在输入值过大或过小时，其导数会非常接近 0。这使得这些区域的梯度几乎为零，导致梯度无法有效传播。
- **影响**：深层网络难以训练，模型无法捕捉长程依赖（在 RNN 中尤为明显）。
- **解决方法**：
    -   使用 ReLU 及其变体（如 Leaky ReLU）作为激活函数。
    -   使用残差连接（如 ResNet）。
    -   使用批归一化（Batch Normalization）。
    -   使用 LSTM 和 GRU 等门控循环单元。

### 梯度爆炸

- **现象**：与梯度消失相反，梯度值在反向传播过程中指数级增大，导致参数更新过大，模型权重剧烈震荡，甚至溢出（NaN），使得训练过程不稳定，模型无法收敛。
- **原因**：
    1.  **链式法则的乘法效应**：如果每层的梯度（例如，激活函数的导数或权重矩阵的范数）都大于 1，那么经过多层相乘后，梯度会迅速变得非常大。
    2.  **不合适的权重初始化**：如果初始权重过大，也容易导致梯度爆炸。
- **影响**：训练不稳定，损失函数值变为 NaN，模型无法学习。
- **解决方法**：
    -   **梯度裁剪 (Gradient Clipping)**：当梯度超过某个阈值时，将其限制在一个预设的最大值内。
    -   使用更小的学习率。
    -   使用批归一化（Batch Normalization）。
    -   使用合适的权重初始化策略。

# 数据预处理与归一化

在将原始数据用于训练机器学习模型之前，通常需要对其进行一系列的准备和转换。

数据预处理涵盖了多种技术，主要包括：

- **数据清洗**：处理数据中的错误、缺失值和异常值。例如，填充缺失的数值，或删除无法修复的样本。
- **数据转换**：将数据转换成更适合模型学习的形式。**归一化** 和 **标准化** 是其中最常见的技术。
- **特征工程**：创建新的特征或选择最有用的特征。这可能包括对现有特征进行组合、分解或编码（如将类别标签转换为数字）。

## 归一化 (Normalization)

归一化的主要目的是将输入数据调整到一个统一的尺度，通常意味着将数据转换到特定的范围（如 $[0, 1]$ 或 $[-1, 1]$），或者使其均值为 0、方差为 1。

- **加速训练**：当不同特征的数值范围相差很大时，梯度下降算法的收敛速度会非常慢。归一化可以使数据空间变得更“圆”，使得梯度下降能更直接地找到最优解。
- **防止梯度爆炸/消失**：在某些激活函数中，输入值过大或过小会导致梯度变得非常小。归一化可以确保输入在激活函数的敏感区域内。
- **提高模型精度**：有些算法（如 K-近邻、支持向量机等）对特征的尺度非常敏感。归一化可以确保所有特征在训练过程中都得到平等的对待。

常见的归一化方法有：

- **最小-最大归一化**：将数据线性地缩放到一个固定的区间，通常是 $[0, 1]$。
    $$ x_{new} = \frac{x - x_{min}}{x_{max} - x_{min}} $$
- **Z-Score 归一化**：将数据转换为均值为 0、标准差为 1 的分布。这是最常用的方法之一。
    $$ x_{new} = \frac{x - \mu}{\sigma} $$

# 过拟合、欠拟合与正则化

在训练机器学习模型时，我们的目标是让模型不仅在训练数据上表现良好，更重要的是在未见过的、新的测试数据上同样表现出色。这种在新数据上的表现能力被称为模型的 **泛化能力（Generalization）**。而过拟合与欠拟合是影响模型泛化能力的两种最常见的问题。

欠拟合 (Underfitting)是指模型在训练集和测试集上的表现都非常差。通常是因为模型过于简单，无法捕捉到数据中复杂的模式和规律。
解决方法为增加模型复杂度（例如增加神经网络的层数或神经元数量）、增加模型的训练轮次等。

过拟合 (Overfitting)是指模型在训练集上表现极好，但在测试集上表现很差。通常是模型过于复杂，以至于把训练数据中的噪声和随机波动也当作规律学习进去，而不是学习数据背后真正的、普适的模式。通常需要降低模型复杂度，或采用正则化（Regularization）等技术。

## 正则化

正则化是一系列旨在防止模型过拟合、提升其泛化能力的技术的总称。它的核心思想是在优化模型的损失函数时，增加一个对模型复杂度进行惩罚的惩罚项。
这个惩罚项用来限制模型的复杂度，通过限制模型复杂度迫使模型去学习更普遍、更具泛化性的特征，从而提高在测试数据上的表现。

### 常见的正则化方法

- **L1 和 L2 正则化**：这两种方法通过在损失函数中增加一个与模型参数（权重）相关的惩罚项来限制权重的大小。
    - **L2 正则化 (Ridge)**: 惩罚项是所有权重平方和的一半。它会使所有权重趋向于接近 0，但不会完全变为 0。在梯度下降更新时，L2 正则化项会导致权重在每次更新时都减去一个与自身大小成正比的量，这个过程被称为 **权重衰退（Weight Decay）**。因此，L2 正则化和权重衰退在实践中常常被认为是等价的。
    - **L1 正则化 (Lasso)**: 惩罚项是所有权重绝对值的和。它能将一些不重要的特征的权重直接变为 0，从而实现 **特征选择**。
- **Dropout**：在训练过程中，**随机**地“丢弃”一部分神经元（即将其输出暂时设为 0）。这迫使网络不能依赖于任何一个特定的神经元，从而防止了神经元之间的复杂协同适应，增强了模型的鲁棒性。
- **数据增强 (Data Augmentation)**：通过对训练数据进行一些变换（如旋转、裁剪、翻转等）来扩充数据集，使得模型能接触到更多样的样本，从而提升泛化能力。