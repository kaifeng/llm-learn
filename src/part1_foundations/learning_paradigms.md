# 机器学习的核心范式

在深入了解具体的模型和算法之前，理解机器学习（Machine Learning, ML）的几种核心“学习范式”至关重要。一个学习范式决定了模型如何从数据中进行学习。

## 1. 监督学习 (Supervised Learning)

这是最常见、最成熟的机器学习范式。

-   **核心思想**：模型从**有标签（labeled）**的数据中学习。数据集中的每个样本都包含一个输入特征（input）和一个期望的输出标签（output/label）。
-   **学习目标**：学习一个从输入到输出的映射函数。模型通过比较自己的预测输出和真实标签之间的差异（即“损失”），来不断调整自身参数，直到能对未见过的新输入做出准确的预测。
-   **好比**：一个学生跟着一位能提供所有练习题标准答案的老师学习。
-   **主要任务**：
    -   **分类 (Classification)**：预测一个离散的类别。例如：判断一封邮件是否是垃圾邮件（二分类），或识别一张图片中的动物是猫、狗还是鸟（多分类）。
    -   **回归 (Regression)**：预测一个连续的数值。例如：根据房屋的面积、位置等特征预测其价格。

-   **典型算法**：除了神经网络，监督学习还包含许多经典算法，如**决策树（Decision Tree）**、支持向量机（SVM）、逻辑回归等。决策树通过构建一个树状的决策模型来进行预测，具有很强的可解释性。

## 2. 无监督学习 (Unsupervised Learning)

-   **核心思想**：模型从**没有标签**的数据中学习。它只能接触到输入数据，必须自己从中发现隐藏的结构、模式或关系。
-   **学习目标**：探索数据内在的结构。
-   **好比**：一个学生没有任何参考答案，只能通过观察和比较，自己将相似的物品归类。
-   **主要任务**：
    -   **聚类 (Clustering)**：将相似的数据点分到同一个簇（cluster）中。例如：根据用户的购买行为将其划分为不同的客户群体。
    -   **降维 (Dimensionality Reduction)**：在保留数据主要信息的前提下，减少数据的特征数量。例如：主成分分析（PCA）。

## 3. 自监督学习 (Self-Supervised Learning, SSL)

自监督学习是近年来推动大语言模型发展的关键技术，它可以看作是无监督学习的一种特殊形式。

-   **核心思想**：同样使用**没有标签**的海量数据，但它巧妙地从数据本身中**自动创建“伪标签”**，从而将问题转化为一个监督学习问题来进行训练。
-   **学习目标**：通过解决一个精心设计的“借口任务（pretext task）”，来让模型学习到关于数据内在结构的、有价值的**表示（representation）**。
-   **好比**：一个学生拿到一张被撕碎的报纸，他通过学习如何将碎片拼接回完整的报纸（借口任务），从而学会了语法、词汇和常识（学到了表示）。
-   **在 LLM 中的应用**：
    -   **掩码语言模型 (Masked Language Modeling)**：随机遮盖句子中的一些词，然后让模型预测被遮盖的词是什么（BERT 使用的方式）。
    -   **下一词预测 (Next Token Prediction)**：根据一段文本的前半部分，让模型预测下一个词是什么（GPT 使用的方式）。

自监督学习是“预训练-微调”范式中**预训练**阶段的理论基础，它使得从未经标注的、海量的互联网文本中学习通用语言知识成为可能。

## 4. 强化学习 (Reinforcement Learning, RL)

-   **核心思想**：模型（称为**智能体 Agent**）通过与一个**环境（Environment）**进行交互来学习。智能体在环境中做出**动作（Action）**，环境会相应地改变**状态（State）**并反馈给智能体一个**奖励（Reward）**或惩罚。
-   **学习目标**：学习一个最优**策略（Policy）**，即在什么状态下应该采取什么动作，以最大化长期累积的总奖励。
-   **好比**：训练一只宠物。当它做出正确的动作（如“坐下”）时，你给它零食（正奖励）；当它做出错误动作时，你不给奖励或进行轻微的惩罚。
-   **在 LLM 中的应用**：
    -   **基于人类反馈的强化学习 (RLHF)**：这是对齐（align）大语言模型、使其回答更有用、更无害的关键技术。人类对模型生成的多个回答进行偏好排序，这些排序被用来训练一个“奖励模型”，然后用这个奖励模型作为环境，通过强化学习来微调语言模型，使其更倾向于生成人类偏好的内容。