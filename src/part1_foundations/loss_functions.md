# 损失函数

**损失函数**定义了模型要优化的目标，即衡量模型预测值与真实值之间的差距。损失函数输出一个数值，该数值代表了单次预测的好坏程度。损失值越大，说明模型的预测越不准确。训练的目标就是最小化损失值。

回归任务的目标是预测一个连续值。

- **均方误差 (Mean Squared Error, MSE)**：也称为 L2 损失。它计算的是预测值与真实值之差的平方的平均值。由于平方的存在，MSE 对较大的误差给予更重的惩罚。
    $$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $$

- **平均绝对误差 (Mean Absolute Error, MAE)**：也称为 L1 损失。它计算的是预测值与真实值之差的绝对值的平均值。相比 MSE，MAE 对异常值不那么敏感，鲁棒性更强。
    $$ \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| $$

分类任务的目标是预测一个离散的类别。

- **交叉熵损失 (Cross-Entropy Loss)**：是分类任务中最常用的损失函数。它衡量的是模型预测的概率分布与真实的概率分布之间的差异。

    - **二元交叉熵 (Binary Cross-Entropy)**：用于二分类问题。输出层只有一个神经元，并使用 Sigmoid 激活函数输出一个概率值 $p$。
        $$ L = -[y \log(p) + (1-y) \log(1-p)] $$
        其中 $y$ 是真实标签（0 或 1），$p$ 是模型预测为类别 1 的概率。

    - **分类交叉熵 (Categorical Cross-Entropy)**：用于多分类问题。输出层有 N 个神经元（N 为类别数），并使用 Softmax 激活函数输出一个概率分布。
        $$ L = -\sum_{i=1}^{N} y_i \log(p_i) $$
        其中 $y_i$ 是一个独热编码的真实标签，$p_i$ 是模型预测为类别 $i$ 的概率。
