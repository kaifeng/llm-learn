# 数据预处理与归一化

在将原始数据用于训练机器学习模型之前，通常需要对其进行一系列的准备和转换。

数据预处理涵盖了多种技术，主要包括：

-   **数据清洗**：处理数据中的错误、缺失值和异常值。例如，填充缺失的数值，或删除无法修复的样本。
-   **数据转换**：将数据转换成更适合模型学习的形式。**归一化** 和 **标准化** 是其中最常见的技术。
-   **特征工程**：创建新的特征或选择最有用的特征。这可能包括对现有特征进行组合、分解或编码（如将类别标签转换为数字）。

## 归一化 (Normalization)

归一化的主要目的是将输入数据调整到一个统一的尺度，通常意味着将数据转换到特定的范围（如 $[0, 1]$ 或 $[-1, 1]$），或者使其均值为 0、方差为 1。

-   **加速训练**：当不同特征的数值范围相差很大时，梯度下降算法的收敛速度会非常慢。归一化可以使数据空间变得更“圆”，使得梯度下降能更直接地找到最优解。
-   **防止梯度爆炸/消失**：在某些激活函数中，输入值过大或过小会导致梯度变得非常小。归一化可以确保输入在激活函数的敏感区域内。
-   **提高模型精度**：有些算法（如 K-近邻、支持向量机等）对特征的尺度非常敏感。归一化可以确保所有特征在训练过程中都得到平等的对待。

常见的归一化方法有：

-   **最小-最大归一化**：将数据线性地缩放到一个固定的区间，通常是 $[0, 1]$。
    $$ x_{new} = \frac{x - x_{min}}{x_{max} - x_{min}} $$
-   **Z-Score 归一化**：将数据转换为均值为 0、标准差为 1 的分布。这是最常用的方法之一。
    $$ x_{new} = \frac{x - \mu}{\sigma} $$
